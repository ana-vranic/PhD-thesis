\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Driving signals}{13}{chapter.2}\protected@file@percent }
\newlabel{Chapter2}{{\M@TitleReference {2}{Driving signals}}{13}{Driving signals}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Growing signals}{13}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Long range correlated signals}{13}{section.2.1}\protected@file@percent }
\citation{makse1996method}
\citation{kantelhardt2001}
\citation{peng1994}
\citation{kantelhardt2002}
\citation{kantelhardt2002}
\citation{ihlen2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Growing network model schema.}}{14}{figure.2.1}\protected@file@percent }
\newlabel{fig:ciljevi}{{\M@TitleReference {2.1}{Growing network model schema.}}{14}{Growing network model schema}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{Multifractal analysis}{14}{figure.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Monofractal signals}}{15}{figure.2.2}\protected@file@percent }
\newlabel{fig:monofractals}{{\M@TitleReference {2.2}{Monofractal signals}}{15}{Monofractal signals}{figure.2.2}{}}
\newlabel{eq:cumsum}{{2.1}{15}{Multifractal analysis}{equation.2.1.1}{}}
\newlabel{eq:var}{{2.2}{15}{Multifractal analysis}{equation.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{Real signals}{16}{equation.2.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets.}}{16}{figure.2.3}\protected@file@percent }
\newlabel{fig:signals}{{\M@TitleReference {2.3}{Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets.}}{16}{Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets}{figure.2.3}{}}
\citation{ihlen2012}
\citation{hajra2004}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref  {fig:signals} obtained with MFDFA. }}{17}{figure.2.4}\protected@file@percent }
\newlabel{fig:mfdfa}{{\M@TitleReference {2.4}{Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref  {fig:signals} obtained with MFDFA. }}{17}{Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref {fig:signals} obtained with MFDFA. }{figure.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Growing network model with aging nodes}{17}{section.2.2}\protected@file@percent }
\newlabel{eq:1}{{2.4}{17}{Growing network model with aging nodes}{equation.2.2.4}{}}
\citation{hajra2004}
\citation{dorogovtsev2001b}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Phase diagram of aging network model}}{18}{figure.2.5}\protected@file@percent }
\newlabel{fig:diagram}{{\M@TitleReference {2.5}{Phase diagram of aging network model}}{18}{Phase diagram of aging network model}{figure.2.5}{}}
\newlabel{eq:aging_master}{{2.5}{18}{Growing network model with aging nodes}{equation.2.2.5}{}}
\citation{tiago2}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Structural differences between networks }{19}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{D-measure}{19}{section.2.3}\protected@file@percent }
\newlabel{eq:dmeasure}{{2.6}{19}{D-measure}{equation.2.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4.}}{20}{figure.2.6}\protected@file@percent }
\newlabel{fig:Ddist_m}{{\M@TitleReference {2.6}{D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4.}}{20}{D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4}{figure.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces The comparison of networks grown with growth signals shown in figure \ref  {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size.}}{21}{figure.2.7}\protected@file@percent }
\newlabel{fig:dmeasure}{{\M@TitleReference {2.7}{The comparison of networks grown with growth signals shown in figure \ref  {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size.}}{21}{The comparison of networks grown with growth signals shown in figure \ref {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size}{figure.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{The assortativity and clustering}{21}{figure.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Aindex}}{22}{figure.2.8}\protected@file@percent }
\newlabel{fig:aindex}{{\M@TitleReference {2.8}{Aindex}}{22}{Aindex}{figure.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class.}}{23}{figure.2.9}\protected@file@percent }
\newlabel{fig:properties_sf}{{\M@TitleReference {2.9}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class.}}{23}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class}{figure.2.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution.}}{23}{figure.2.10}\protected@file@percent }
\newlabel{fig:properties_se}{{\M@TitleReference {2.10}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution.}}{23}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution}{figure.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties.}}{24}{figure.2.11}\protected@file@percent }
\newlabel{fig:properties_sw}{{\M@TitleReference {2.11}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties.}}{24}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties}{figure.2.11}{}}
\citation{mitrovic2012}
\citation{mitrovic2015}
\citation{hajra2004}
\citation{tiago2}
\citation{hajra2004}
\citation{boccaletti2006}
\citation{boccaletti2006}
\citation{boccaletti2006}
\citation{mitrovic2015}
\citation{mitrovic2012}
\citation{mitrovic2015}
\citation{suvakov2013}
\citation{holme2012}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Conclusions}{25}{section.2.4}\protected@file@percent }
\@setckpt{Chapters/Chapter_DrivingSignal}{
\setcounter{page}{27}
\setcounter{equation}{5}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{1}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{29}
\setcounter{lastsheet}{82}
\setcounter{lastpage}{80}
\setcounter{figure}{11}
\setcounter{lofdepth}{1}
\setcounter{table}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{1}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{bookmark@seq@number}{12}
\setcounter{AM@survey}{0}
\setcounter{section@level}{0}
}
