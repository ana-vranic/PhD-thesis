\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{makse1996method}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Driving signals}{31}{chapter.2}\protected@file@percent }
\newlabel{Chapter2}{{\M@TitleReference {2}{Driving signals}}{31}{Driving signals}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Growing signals}{31}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Long range correlated signals}{31}{subsection.2.1.1}\protected@file@percent }
\citation{kantelhardt2001}
\citation{peng1994}
\citation{kantelhardt2002}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Growing network model schema.}}{32}{figure.2.1}\protected@file@percent }
\newlabel{fig:ciljevi}{{\M@TitleReference {2.1}{Growing network model schema.}}{32}{Growing network model schema}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Real signals}{32}{subsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Monofractal signals}}{33}{figure.2.2}\protected@file@percent }
\newlabel{fig:monofractals}{{\M@TitleReference {2.2}{Monofractal signals}}{33}{Monofractal signals}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets.}}{33}{figure.2.3}\protected@file@percent }
\newlabel{fig:signals}{{\M@TitleReference {2.3}{Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets.}}{33}{Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets}{figure.2.3}{}}
\citation{ihlen2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref  {fig:signals} obtained with MFDFA. }}{34}{figure.2.4}\protected@file@percent }
\newlabel{fig:mfdfa}{{\M@TitleReference {2.4}{Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref  {fig:signals} obtained with MFDFA. }}{34}{Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref {fig:signals} obtained with MFDFA. }{figure.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Growing network model with aging nodes}{34}{section.2.2}\protected@file@percent }
\newlabel{eq:aging_master}{{2.1}{34}{Growing network model with aging nodes}{equation.2.2.1}{}}
\citation{dorogovtsev2001b}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Structural differences between networks }{35}{section.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4.}}{36}{figure.2.5}\protected@file@percent }
\newlabel{fig:Ddist_m}{{\M@TitleReference {2.5}{D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4.}}{36}{D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4}{figure.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}The assortativity and clustering}{36}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The comparison of networks grown with growth signals shown in figure \ref  {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size.}}{37}{figure.2.6}\protected@file@percent }
\newlabel{fig:dmeasure}{{\M@TitleReference {2.6}{The comparison of networks grown with growth signals shown in figure \ref  {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size.}}{37}{The comparison of networks grown with growth signals shown in figure \ref {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size}{figure.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Aindex}}{37}{figure.2.7}\protected@file@percent }
\newlabel{fig:aindex}{{\M@TitleReference {2.7}{Aindex}}{37}{Aindex}{figure.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class.}}{38}{figure.2.8}\protected@file@percent }
\newlabel{fig:properties_sf}{{\M@TitleReference {2.8}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class.}}{38}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class}{figure.2.8}{}}
\citation{mitrovic2012}
\citation{mitrovic2015}
\citation{hajra2004}
\citation{tiago2}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution.}}{39}{figure.2.9}\protected@file@percent }
\newlabel{fig:properties_se}{{\M@TitleReference {2.9}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution.}}{39}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution}{figure.2.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties.}}{39}{figure.2.10}\protected@file@percent }
\newlabel{fig:properties_sw}{{\M@TitleReference {2.10}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties.}}{39}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties}{figure.2.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Conclusions}{39}{section.2.4}\protected@file@percent }
\citation{hajra2004}
\citation{boccaletti2006}
\citation{boccaletti2006}
\citation{boccaletti2006}
\citation{mitrovic2015}
\citation{mitrovic2012}
\citation{mitrovic2015}
\citation{suvakov2013}
\citation{holme2012}
\@setckpt{1-MainMatter/Chapter_DrivingSignal}{
\setcounter{page}{41}
\setcounter{equation}{1}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{2}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{41}
\setcounter{lastsheet}{45}
\setcounter{lastpage}{45}
\setcounter{figure}{10}
\setcounter{lofdepth}{1}
\setcounter{table}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{bookmark@seq@number}{35}
\setcounter{AM@survey}{0}
\setcounter{KVtest}{1}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{float@type}{4}
\setcounter{section@level}{0}
}
