\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Driving signals}{1}{chapter.1}\protected@file@percent }
\newlabel{Ch:signals}{{\M@TitleReference {1}{Driving signals}}{1}{Driving signals}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Growing network model with aging nodes}{1}{section.1.1}\protected@file@percent }
\newlabel{eq:aging_master}{{1.1}{1}{Growing network model with aging nodes}{equation.1.1.1}{}}
\citation{dorogovtsev2001b}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The open question is how nonlinear signals in combination with network model influence the structure of the network. Under what circumstances networks have the scale-free, hub-spoke or chain structure. }}{2}{figure.1.1}\protected@file@percent }
\newlabel{fig:ciljevi}{{\M@TitleReference {1.1}{The open question is how nonlinear signals in combination with network model influence the structure of the network. Under what circumstances networks have the scale-free, hub-spoke or chain structure. }}{2}{The open question is how nonlinear signals in combination with network model influence the structure of the network. Under what circumstances networks have the scale-free, hub-spoke or chain structure. }{figure.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Real signals}{2}{section.1.2}\protected@file@percent }
\citation{ihlen2012}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets.}}{4}{figure.1.2}\protected@file@percent }
\newlabel{fig:signals}{{\M@TitleReference {1.2}{Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets.}}{4}{Growth signals for TECH (a) and MySpace (b) social groups, their randomized counterparts, and random signal drawn from Poasonian distribution with mean $1$. The cumulative signals are shown in insets}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref  {fig:signals} obtained with MFDFA. }}{4}{figure.1.3}\protected@file@percent }
\newlabel{fig:mfdfa}{{\M@TitleReference {1.3}{Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref  {fig:signals} obtained with MFDFA. }}{4}{Dependence of Hurst exponent on parameter $q$ for all five signals shown in figure \ref {fig:signals} obtained with MFDFA. }{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class.}}{5}{figure.1.4}\protected@file@percent }
\newlabel{fig:properties_sf}{{\M@TitleReference {1.4}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class.}}{5}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $\alpha =-1.0$, $\beta =1.5$ and $L=2$ for all networks. The networks are from scale-free class}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution.}}{6}{figure.1.5}\protected@file@percent }
\newlabel{fig:properties_se}{{\M@TitleReference {1.5}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution.}}{6}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $L=2, \alpha =-1.5$, $\beta =1.5$. The networks have stretched exponential degree distribution}{figure.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties.}}{6}{figure.1.6}\protected@file@percent }
\newlabel{fig:properties_sw}{{\M@TitleReference {1.6}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties.}}{6}{Degree distribution, the dependence of average first neighbor degree on node degree, dependence of node clustering on node degree for networks grown with different time-varying and constant signals. Model parameters have value $ L=2, \alpha =-1.0$, $\beta =2.0$. Generated networks have scale-free properties}{figure.1.6}{}}
\citation{makse1996method}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces The comparison of networks grown with growth signals shown in figure \ref  {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size.}}{7}{figure.1.7}\protected@file@percent }
\newlabel{fig:dmeasure}{{\M@TitleReference {1.7}{The comparison of networks grown with growth signals shown in figure \ref  {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size.}}{7}{The comparison of networks grown with growth signals shown in figure \ref {fig:signals} versus ones grown with constant signal $M=1$, for value of parameter $\alpha \in [-3,-1]$ and $\beta \in [1,3]$. $M(t)$ is the number of new nodes, and $L$ is the number of links added to the network in each time step. The compared networks are of the same size}{figure.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Long range correlated signals}{8}{section.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Monofractal signals}}{8}{figure.1.8}\protected@file@percent }
\newlabel{fig:monofractals}{{\M@TitleReference {1.8}{Monofractal signals}}{8}{Monofractal signals}{figure.1.8}{}}
\citation{mitrovic2012}
\citation{mitrovic2015}
\citation{hajra2004}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Aindex}}{9}{figure.1.9}\protected@file@percent }
\newlabel{fig:aindex}{{\M@TitleReference {1.9}{Aindex}}{9}{Aindex}{figure.1.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Conclusions}{9}{section.1.4}\protected@file@percent }
\citation{tiago2}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4.}}{10}{figure.1.10}\protected@file@percent }
\newlabel{fig:Ddist_m}{{\M@TitleReference {1.10}{D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4.}}{10}{D-distance between networks generated with different long-range correlated signals with fixed value of Hurst exponent and networks generated with constant signal M=4}{figure.1.10}{}}
\citation{hajra2004}
\citation{boccaletti2006}
\citation{boccaletti2006}
\citation{boccaletti2006}
\citation{mitrovic2015}
\citation{mitrovic2012}
\citation{mitrovic2015}
\citation{suvakov2013}
\citation{holme2012}
\@setckpt{1-MainMatter/Chapter_DrivingSignal}{
\setcounter{page}{12}
\setcounter{equation}{1}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{2}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{12}
\setcounter{lastsheet}{13}
\setcounter{lastpage}{13}
\setcounter{figure}{10}
\setcounter{lofdepth}{1}
\setcounter{table}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{bookmark@seq@number}{5}
\setcounter{AM@survey}{0}
\setcounter{KVtest}{1}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{float@type}{4}
\setcounter{section@level}{0}
}
